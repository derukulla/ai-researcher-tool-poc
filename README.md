# AI Researcher Evaluation Tool

A comprehensive system for evaluating AI researchers based on their education, publications, patents, work experience, and GitHub contributions.

## Features

- **Multi-source Analysis**: Evaluates CVs and LinkedIn profiles
- **Comprehensive Scoring**: Education, Publications, Patents, Work Experience, GitHub
- **Real-time Processing**: Live API integration with Google Scholar, Patents, GitHub
- **Smart Filtering**: Advanced filters for education, publications, patents, and more
- **Rate Limit Handling**: Robust error handling with user-friendly messages
- **Score Justification**: Detailed breakdown of how scores are calculated
- **Source Traceability**: Every data point shows which source it came from and reliability
- **Parallel Processing**: Lightning-fast multi-profile evaluation with concurrent parsing
- **Excel Export**: Comprehensive Excel export with 68+ detailed fields for analysis

> **ğŸš€ For Power Users**: Run tests directly in terminal for **detailed logs, complete API responses, step-by-step processing**, and comprehensive debugging information not available in the web interface.

##  Architecture

```
â”œâ”€â”€ client/          # React TypeScript frontend
â”œâ”€â”€ server/          # Node.js Express backend
â”‚   â”œâ”€â”€ routes/      # API endpoints
â”‚   â”œâ”€â”€ utils/       # Core parsing and scoring logic
â”‚   â”œâ”€â”€ cache/       # API response caching
â”‚   â””â”€â”€ tests/       # Server-side test scripts
â”œâ”€â”€ tests/           # Main evaluation test scripts
â””â”€â”€ profiles/        # Sample CV files
```

##  Quick Setup

### Prerequisites
- **Node.js** (v16+ recommended)
- **npm** or **yarn**

### Step 1: Clone & Install
```bash
# Clone the repository
git clone https://github.com/derukulla/ai-researcher-tool-poc.git
cd ai-researcher-tool-poc

# Install all dependencies (server + client)
npm run install-all
```

### Step 2: Configure API Keys
```bash
nano server/config/apiKeys.js  
```

**Update the following keys in `server/config/apiKeys.js`:**
```javascript
// Required API Keys - Replace with your actual keys
SERPAPI: {
  key: 'your_serpapi_key_here',           // For Google Scholar + Patents
},
PDL: {
  key: 'your_people_data_labs_key_here',  // For LinkedIn data  
},
GITHUB: {
  key: 'your_github_token_here',          // For GitHub analysis
},

// Optional
GEMINI: {
  key: 'your_gemini_key_here',            // For enhanced AI processing
}
```

### Step 3: Start the Application
```bash
# Option A: Start both server and client
npm run dev

# Option B: Start individually
npm run server    # Backend (http://localhost:5000)
npm run client    # Frontend (http://localhost:3000)
```

##  Usage

### Web Interface (Recommended)
1. Open http://localhost:3000
2. Choose between "Score CV/Profile" or "Get Top Researchers"
3. For CV evaluation: Upload CV or enter LinkedIn profile
4. For researcher search: Configure filters and search LinkedIn profiles
5. View detailed evaluation results and export to Excel

### Terminal Testing (For Detailed Logs)
```bash
# Test CV evaluation
node tests/testCVEvaluation.js profiles/3.pdf

# Test LinkedIn evaluation  
node tests/testLinkedInEvaluation.js parthapratimtalukdar

# Or use npm scripts
npm run test-cv profiles/3.pdf
npm run test-linkedin parthapratimtalukdar
```

**Getting API Keys:**
- **SerpAPI**: Sign up at [serpapi.com](https://serpapi.com) (Google Scholar + Patents)
- **People Data Labs**: Get key at [peopledatalabs.com](https://www.peopledatalabs.com)
- **GitHub**: Create token at [github.com/settings/tokens](https://github.com/settings/tokens)
- **Gemini**: Get key at [ai.google.dev](https://ai.google.dev)

## Running the Application

> **ğŸ“ Quick Start for Detailed Analysis**: Want to see **everything**? Skip the web interface and run terminal tests directly:
> ```bash
> node tests/testCVEvaluation.js profiles/3.pdf
> node tests/testLinkedInEvaluation.js linkedinid
> ```
> This shows complete logs, API responses, parsing details, scoring breakdowns, and **source justification** for every data point!

### Method 1: Full Application (Recommended)

**Start the backend:**
```bash
cd server
npm start
# Server runs on http://localhost:5000
```

**Start the frontend:**
```bash
cd client
npm start
# Frontend runs on http://localhost:3000
```

**Access the application:**
Open [http://localhost:3000](http://localhost:3000) in your browser.

> **ğŸ’¡ Tip**: When you start the server, you'll see a configuration status showing which API keys are configured:
> ```
> ğŸ”‘ API Keys Configuration Status:
> âœ… SERPAPI: Configured (Required)
> âœ… PDL: Configured (Required)  
> âœ… GITHUB: Configured (Required)
> âš ï¸ GEMINI: Not configured (Optional)
> âœ… All required API keys are configured!
> ```

### Method 2: Terminal Testing

> **ğŸ’¡ Pro Tip**: Use terminal testing for **detailed logs, debugging, and comprehensive analysis**. Terminal output shows complete API responses, parsing details, scoring breakdowns, source justification, and step-by-step processing that's not visible in the web interface.

**Test LinkedIn Profile:**
```bash
node tests/testLinkedInEvaluation.js <linkedin_username>
```

**Test CV Upload:**
```bash
node tests/testCVEvaluation.js <path_to_cv_file>

# Examples (run from project root):
node tests/testCVEvaluation.js ../profiles/1.pdf
node tests/testCVEvaluation.js ../profiles/3.pdf
node tests/testCVEvaluation.js /absolute/path/to/resume.pdf
```

**Test Parallel Processing:**
```bash
# Compare parallel vs sequential performance
node tests/testParallelProfileSearch.js

# Or using npm script
npm run test-parallel
```

**What You Get in Terminal:**
- ğŸ” **Detailed Parsing**: See exactly what data is extracted from each source
- ğŸ“Š **API Responses**: Full responses from Google Scholar, GitHub, Patents APIs  
- âš™ï¸ **Processing Steps**: Step-by-step evaluation pipeline
- ğŸ› **Debug Info**: Error messages, cache status, API call details
- ğŸ“ˆ **Scoring Breakdown**: Detailed score calculations and weightings
- ğŸ”‘ **API Status**: Real-time API key validation and usage stats
- ğŸ“‹ **Source Justification**: See which sources contributed to each data point and reliability scores
- âš¡ **Performance Metrics**: Compare parallel vs sequential processing speeds

## âš¡ Parallel Processing Architecture

The system now supports **parallel processing** for dramatically faster multi-profile evaluation:

### **Sequential vs Parallel Processing:**

**ğŸŒ Sequential (Original):**
```
Profile 1: Education â†’ Publications â†’ Patents â†’ GitHub â†’ Work Experience
Profile 2: Education â†’ Publications â†’ Patents â†’ GitHub â†’ Work Experience  
Profile 3: Education â†’ Publications â†’ Patents â†’ GitHub â†’ Work Experience
```

**âš¡ Parallel (New):**
```
Stage 1: Education parsing for ALL profiles simultaneously
Stage 2: Filter â†’ Publications parsing for remaining profiles in parallel
Stage 3: Filter â†’ Patents parsing for remaining profiles in parallel  
Stage 4: Filter â†’ GitHub parsing for remaining profiles in parallel
Stage 5: Filter â†’ Work experience parsing for remaining profiles in parallel
```

### **Performance Benefits:**
- **3-5x faster** processing for multiple profiles
- **Intelligent batching** to respect API rate limits
- **Early filtering** reduces unnecessary API calls
- **Concurrent processing** maximizes throughput

### **Usage:**
```javascript
// Use parallel processing for multiple profiles
const { profileSearchParallel } = require('./utils/profileSearch');
const results = await profileSearchParallel(filters, options);

// Compare with sequential for single profiles
const { profileSearch } = require('./utils/profileSearch');
const results = await profileSearch(filters, options);
```

##  How It Works

### Evaluation Process

1. **Profile Parsing**
   - Extract name, education, experience from CV/LinkedIn
   - Parse degrees, institutions, field of study

2. **Publications Analysis** 
   - Search Google Scholar for researcher's publications
   - Calculate H-index, citation count, publication venues
   - Categorize venues (top AI conferences, journals, etc.)

3. **Patents Research**
   - Search patent databases for inventor patents
   - Identify first inventor vs co-inventor patents
   - Analyze AI-related patent contributions

4. **GitHub Analysis**
   - Find researcher's GitHub profile
   - Analyze repository volume, popularity, commit frequency
   - Assess code quality and project relevance

5. **Work Experience Evaluation**
   - Identify work at top AI organizations
   - Assess impact quality and mentorship roles
   - Evaluate deep learning framework experience

6. **Final Scoring**
   - Weighted combination of all factors
   - Default weights: Education (25%), Publications (30%), Patents (13%), Work Experience (30%), GitHub (2%)
   - Score breakdown and justification provided

### Scoring Criteria

- **Education (0-10)**: Degree level, institution prestige, field relevance
- **Publications (0-10)**: Count, citations, H-index, venue quality  
- **Patents (0-10)**: Granted patents as first/co-inventor
- **Work Experience (0-10)**: Top AI orgs, impact quality, mentorship
- **GitHub (0-10)**: Repository volume, popularity, activity

##  Usage Examples

### Web Interface

1. **Score CV/Profile Mode**:
   - Upload CV files (PDF/DOC) for analysis
   - Enter LinkedIn username or profile ID
   - Adjust custom scoring weights
   - View detailed score breakdown

2. **Get Top Researchers Mode**:
   - Configure education, publications, patents, work experience filters
   - Search LinkedIn profiles with AI-powered analysis
   - Export comprehensive results to Excel (68+ fields)
   - Apply filters and download matching profiles

### Excel Export Features

The system generates comprehensive Excel exports with 68+ fields including:

- **Basic Info**: Name, LinkedIn details, title, passed filters
- **Education**: Degree, institute, field, scores
- **Publications**: Count, citations, H-index, venue quality, research areas
- **Patents**: First inventor, co-inventor, filed patents, scores
- **GitHub**: Profile details, repository analysis, AI relevance
- **Work Experience**: AI organizations, impact quality, frameworks, reasoning
- **Scoring**: Raw scores, weighted scores, individual weights used

##  Development

### Server Structure
```
server/
â”œâ”€â”€ index.js                 # Main server entry point
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ evaluation.js        # CV and LinkedIn evaluation endpoints
â”‚   â”œâ”€â”€ researchers.js       # Researcher data management
â”‚   â”œâ”€â”€ profileSearch.js     # LinkedIn profile search endpoints
â”‚   â””â”€â”€ cache.js             # Cache management endpoints
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ aiProfileParser.js   # Education and profile parsing
â”‚   â”œâ”€â”€ publicationsParser.js # Google Scholar integration
â”‚   â”œâ”€â”€ patentParser.js      # Patent search and analysis
â”‚   â”œâ”€â”€ githubParser.js      # GitHub profile analysis
â”‚   â”œâ”€â”€ workExperienceParser.js # Experience parsing
â”‚   â”œâ”€â”€ scoringEngine.js     # Score calculation
â”‚   â”œâ”€â”€ profileSearch.js     # LinkedIn profile search logic
â”‚   â”œâ”€â”€ linkedinCache.js     # LinkedIn profile caching
â”‚   â””â”€â”€ linkedinFormatter.js # LinkedIn data formatting
â””â”€â”€ tests/                   # Development test scripts
```

### Client Structure
```
client/src/
â”œâ”€â”€ components/              # React components
â”‚   â”œâ”€â”€ ModeSelector.tsx     # Mode selection interface
â”‚   â”œâ”€â”€ ProfileEvaluator.tsx # CV/LinkedIn evaluation interface
â”‚   â”œâ”€â”€ FilterPanel.tsx     # Search filters with Excel export
â”‚   â”œâ”€â”€ ProfileSearchResults.tsx # LinkedIn search results
â”‚   â””â”€â”€ ResearcherList.tsx  # Results display
â”œâ”€â”€ services/
â”‚   â””â”€â”€ api.ts              # API service layer
â””â”€â”€ types/
    â””index.ts            # TypeScript definitions
```

##  API Endpoints

- `POST /api/evaluation/cv` - Evaluate uploaded CV file
- `POST /api/evaluation/linkedin` - Evaluate LinkedIn profile
- `POST /api/profile-search/search` - Search LinkedIn profiles with filters
- `GET /api/cache/stats` - Get LinkedIn cache statistics
- `DELETE /api/cache/clear` - Clear LinkedIn profile cache
- `POST /api/scoring/calculate` - Calculate scores with custom weights

##  Error Handling

The system handles various error scenarios:

- **Rate Limits**: Clear messages when API limits are exceeded with caching fallbacks
- **Network Issues**: Graceful degradation and retry suggestions  
- **Invalid Files**: Helpful error messages for unsupported formats
- **Missing Data**: Fallback values when information isn't available
- **API Failures**: Robust error handling with detailed logging

## ğŸ”§ Caching System

The application includes intelligent caching for performance optimization:

- **LinkedIn Profile Caching**: Stores profiles for 30 days to reduce API calls
- **GitHub API Caching**: Caches GitHub profile data and repository analysis
- **Publications Caching**: Stores Google Scholar search results
- **Memory + File Caching**: Dual-layer caching for optimal performance
- **Cache Management**: Built-in cache cleanup and statistics tracking

---

